{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PySpark\n",
    "\n",
    "Spark is a powerful, general purpose tool for working with Big Data. Spark transparently handles the distribution of compute tasks across a cluster. This means that operations are fast, but it also allows you to focus on the analysis rather than worry about technical details. In this course you'll learn how to get data into Spark and then delve into the three fundamental Spark Machine Learning algorithms: Linear Regression, Logistic Regression/Classifiers, and creating pipelines. Along the way you'll analyse a large dataset of flight delays and spam text messages. With this background you'll be ready to harness the power of Spark and apply it on your own Machine Learning projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Spark is a framework for working with Big Data. In this chapter you'll cover some background about Spark and Machine Learning. You'll then find out how to connect to Spark using Python and load CSV data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a SparkSession\n",
    "In this exercise, you'll spin up a local Spark cluster using all available cores. The cluster will be accessible via a SparkSession object.\n",
    "\n",
    "The SparkSession class has a builder attribute, which is an instance of the Builder class. The Builder class exposes three important methods that let you:\n",
    "\n",
    "specify the location of the master node;\n",
    "name the application (optional); and\n",
    "retrieve an existing SparkSession or, if there is none, create a new one.\n",
    "The SparkSession class has a version attribute which gives the version of Spark.\n",
    "\n",
    "Find out more about SparkSession here.\n",
    "\n",
    "Once you are finished with the cluster, it's a good idea to shut it down, which will free up its resources, making them available for other processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.2\n"
     ]
    }
   ],
   "source": [
    "# Import the PySpark module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('test') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "# What version of Spark?\n",
    "print(spark.version)\n",
    "\n",
    "# Terminate the cluster\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The session object will now allow us to load data into Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading flights data\n",
    "In this exercise you're going to load some airline flight data from a CSV file. To ensure that the exercise runs quickly these data have been trimmed down to only 50 000 records. You can get a larger dataset in the same format here.\n",
    "\n",
    "Notes on CSV format:\n",
    "\n",
    "fields are separated by a comma (this is the default separator) and\n",
    "missing data are denoted by the string 'NA'.\n",
    "Data dictionary:\n",
    "\n",
    "- mon — month (integer between 1 and 12)\n",
    "- dom — day of month (integer between 1 and 31)\n",
    "- dow — day of week (integer; 1 = Monday and 7 = Sunday)\n",
    "- org — origin airport (IATA code)\n",
    "- mile — distance (miles)\n",
    "- carrier — carrier (IATA code)\n",
    "- depart — departure time (decimal hour)\n",
    "- duration — expected duration (minutes)\n",
    "- delay — delay (minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 146558 records.\n",
      "+-----------------+-------------+-------------------+-----------------------------+\n",
      "|Date (MM/DD/YYYY)|Flight Number|Destination Airport|Actual elapsed time (Minutes)|\n",
      "+-----------------+-------------+-------------------+-----------------------------+\n",
      "|       01/01/2015|            5|                HNL|                          526|\n",
      "|       01/01/2015|            7|                OGG|                          517|\n",
      "|       01/01/2015|           23|                SFO|                          233|\n",
      "|       01/01/2015|           27|                LAS|                          165|\n",
      "|       01/01/2015|           29|                ONT|                            0|\n",
      "+-----------------+-------------+-------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Date (MM/DD/YYYY)', 'string'),\n",
       " ('Flight Number', 'int'),\n",
       " ('Destination Airport', 'string'),\n",
       " ('Actual elapsed time (Minutes)', 'int')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File Path\n",
    "file_path = \".../data/datacamp/\"\n",
    "\n",
    "# Read data from CSV file\n",
    "flights = spark.read.csv(file_path + 'flights_csv/2015-departures.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % flights.count())\n",
    "\n",
    "# View the first five records\n",
    "flights.show(5)\n",
    "\n",
    "# Check column data types\n",
    "flights.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:playground_py36]",
   "language": "python",
   "name": "conda-env-playground_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
