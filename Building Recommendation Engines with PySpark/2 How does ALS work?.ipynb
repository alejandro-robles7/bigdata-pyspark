{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct format and distinct users\n",
    "Take a look at the R dataframe. Notice that it is in conventional or \"wide\" format with a different movie in each column. Also notice that the User's and movie names are not in integer format. Follow the steps to properly prepare this data for ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+----------+----------------+\n",
      "|Coco|Shrek|Sneakers|Swing Kids|            User|\n",
      "+----+-----+--------+----------+----------------+\n",
      "|   4|    3|       3|         4|    James Alking|\n",
      "|   5|    4|       2|      null|Elvira Marroquin|\n",
      "|   2| null|       5|         2|      Jack Bauer|\n",
      "|null|    5|       2|         2|     Julia James|\n",
      "+----+-----+--------+----------+----------------+\n",
      "\n",
      "+----------------+----------+------+\n",
      "|            User|     Movie|Rating|\n",
      "+----------------+----------+------+\n",
      "|    James Alking|      Coco|     4|\n",
      "|    James Alking|     Shrek|     3|\n",
      "|    James Alking|  Sneakers|     3|\n",
      "|    James Alking|Swing Kids|     4|\n",
      "|Elvira Marroquin|      Coco|     5|\n",
      "|Elvira Marroquin|     Shrek|     4|\n",
      "|Elvira Marroquin|  Sneakers|     2|\n",
      "|      Jack Bauer|      Coco|     2|\n",
      "|      Jack Bauer|  Sneakers|     5|\n",
      "|      Jack Bauer|Swing Kids|     2|\n",
      "|     Julia James|     Shrek|     5|\n",
      "|     Julia James|  Sneakers|     2|\n",
      "|     Julia James|Swing Kids|     2|\n",
      "+----------------+----------+------+\n",
      "\n",
      "+----------------+------+\n",
      "|            User|userId|\n",
      "+----------------+------+\n",
      "|     Julia James|     0|\n",
      "|    James Alking|     1|\n",
      "|      Jack Bauer|     2|\n",
      "|Elvira Marroquin|     3|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import monotonically_increasing_id and show R\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "#from pyspark.sql.functions import explode\n",
    "R = spark.createDataFrame(R)\n",
    "R.show()\n",
    "\n",
    "# Use the to_long() function to convert the dataframe to the \"long\" format.\n",
    "ratings = to_long(R)\n",
    "ratings.show()\n",
    "\n",
    "# Get unique users and repartition to 1 partition\n",
    "users = ratings.select(\"User\").distinct().coalesce(1)\n",
    "\n",
    "# Create a new column of unique integers called \"userId\" in the users dataframe.\n",
    "users = users.withColumn(\"userId\", monotonically_increasing_id()).persist()\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning integer id's to movies\n",
    "Let's do the same thing to the movies. Then let's join the new user IDs and movie IDs into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+------+-------+\n",
      "|     Movie|            User|Rating|userId|movieId|\n",
      "+----------+----------------+------+------+-------+\n",
      "|     Shrek|     Julia James|     5|     0|      0|\n",
      "|     Shrek|    James Alking|     3|     1|      0|\n",
      "|     Shrek|Elvira Marroquin|     4|     3|      0|\n",
      "|      Coco|    James Alking|     4|     1|      1|\n",
      "|      Coco|Elvira Marroquin|     5|     3|      1|\n",
      "|      Coco|      Jack Bauer|     2|     2|      1|\n",
      "|  Sneakers|Elvira Marroquin|     2|     3|      2|\n",
      "|  Sneakers|      Jack Bauer|     5|     2|      2|\n",
      "|  Sneakers|    James Alking|     3|     1|      2|\n",
      "|  Sneakers|     Julia James|     2|     0|      2|\n",
      "|Swing Kids|      Jack Bauer|     2|     2|      3|\n",
      "|Swing Kids|    James Alking|     4|     1|      3|\n",
      "|Swing Kids|     Julia James|     2|     0|      3|\n",
      "+----------+----------------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the distinct movie id's\n",
    "movies = ratings.select(\"Movie\").distinct() \n",
    "\n",
    "# Repartition the data to have only one partition.\n",
    "movies = movies.coalesce(1) \n",
    "\n",
    "# Create a new column of movieId integers. \n",
    "movies = movies.withColumn(\"movieId\", monotonically_increasing_id()).persist() \n",
    "\n",
    "# Join the ratings, users and movies dataframes\n",
    "movie_ratings = ratings.join(users, \"User\", \"left\").join(movies, \"Movie\", \"left\")\n",
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Out An ALS Model\n",
    "Let's specify your first ALS model. Complete the code below to build your first ALS model.\n",
    "\n",
    "Recall that you can use the .columns method on the ratings data frame to see what the names of the columns are that contain user, movie, and ratings data. Spark needs to know the names of these columns in order to perform ALS correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+------+-------+----------+\n",
      "|     Movie|            User|Rating|userId|movieId|prediction|\n",
      "+----------+----------------+------+------+-------+----------+\n",
      "|  Sneakers|Elvira Marroquin|     2|     3|      2| 2.8755982|\n",
      "|     Shrek|Elvira Marroquin|     4|     3|      0| 3.4584947|\n",
      "|Swing Kids|      Jack Bauer|     2|     2|      3| 2.8047183|\n",
      "+----------+----------------+------+------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Rating to Numeric\n",
    "from pyspark.sql.types import IntegerType\n",
    "movie_ratings = movie_ratings.withColumn(\"Rating\", movie_ratings.Rating.cast(\"integer\"))\n",
    "\n",
    "# Split the ratings dataframe into training and test data\n",
    "(training_data, test_data) = movie_ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Set the ALS hyperparameters\n",
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"Rating\", rank = 10, maxIter = 15, regParam = .1,\n",
    "          coldStartStrategy=\"drop\", nonnegative = True, implicitPrefs = False)\n",
    "\n",
    "# Fit the mdoel to the training_data\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Generate predictions on the test_data\n",
    "test_predictions = model.transform(test_data)\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RMSE Evaluator\n",
    "Now that you know how to fit a model to training data and generate test predictions, you need a way to evaluate how well your model performs. For this we'll build an evaluator. Evaluators in Spark can be built out in various ways. For our purposes, we want a regressionEvaluator that calculates the RMSE. After we build our regressionEvaluator, we can fit the model to our data and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse\n",
      "Rating\n",
      "prediction\n"
     ]
    }
   ],
   "source": [
    "# Import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Complete the evaluator code\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Extract the 3 parameters\n",
    "print(evaluator.getMetricName())\n",
    "print(evaluator.getLabelCol())\n",
    "print(evaluator.getPredictionCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get RMSE\n",
    "Now that you know how to build a model and generate predictions, and have an evaluator to tell us how well it predicts ratings, we can calculate the RMSE to see how well an ALS model performed. We'll use the evaluator that we built in the previous exercise to calculate and print the rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7544251002111148\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the \"predictions\" dataframe\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# Print the RMSE\n",
    "print (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work. This RMSE means that on average, the model's test predictions are about .75 off from the true values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:playground_py36]",
   "language": "python",
   "name": "conda-env-playground_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
