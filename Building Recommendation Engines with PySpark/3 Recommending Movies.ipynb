{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending Movies\n",
    "In this chapter you will be introduced to the MovieLens dataset. You will walk through how to assess it's use for ALS, build out a full cross-validated ALS model on it, and learn how to evaluate it's performance. This will be the foundation for all subsequent ALS models you build using Pyspark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the MovieLens Data\n",
    "Familiarize yourself with the ratings dataset provided here. Would you consider the data to be implicit or explicit ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userId', 'movieId', 'rating', 'timestamp']\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|   514|    799|   3.0| 853893138|\n",
      "|   560|   2513|   4.0|1452851841|\n",
      "|   253|   2688|   1.5|1215832619|\n",
      "|    15|  34334|   1.5|1367765144|\n",
      "|   285|   1748|   2.0| 965088503|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# File Path\n",
    "file_path = \".../data/datacamp/\"\n",
    "\n",
    "# Load in data\n",
    "ratings = spark.read.parquet(file_path + 'ratings')\n",
    "\n",
    "# Look at the column names\n",
    "print(ratings.columns)\n",
    "\n",
    "# Look at the first few rows of data\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. This dataset includes ratings from the customers. This indicates that these are explicit ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sparsity\n",
    "As you know, ALS works well with sparse datasets. Let's see how much of the ratings matrix is actually empty.\n",
    "\n",
    "Remember that sparsity is calculated by the number of cells in a matrix that contain a rating divided by the total number of values that matrix could hold given the number of users and items (movies). In other words, dividing the number of ratings present in the matrix by the product of users and movies in the matrix and subtracting that from 1 will give us the sparsity or the percentage of the ratings matrix that is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.36% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, this matrix is more than 98% empty. That's a lot of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GroupBy and Filter Methods\n",
    "Now that we know a little more about the dataset, let's look at some general summary metrics of the ratings dataset and see how many ratings the movies have and how many ratings each users has provided.\n",
    "\n",
    "Two common methods that will be helpful to you as you aggregate summary statistics in Spark are the .filter() and the .groupBy() methods. The .filter() method allows you to filter out any data that doesn't meet your specified criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|   514|    799|   3.0| 853893138|\n",
      "|   560|   2513|   4.0|1452851841|\n",
      "|   253|   2688|   1.5|1215832619|\n",
      "|    15|  34334|   1.5|1367765144|\n",
      "|   285|   1748|   2.0| 965088503|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|    15|  34334|   1.5|1367765144|\n",
      "|    30|    532|   2.0| 945277742|\n",
      "|    74|   1722|   5.0| 942704332|\n",
      "|     8|   5952|   4.0|1154464762|\n",
      "|    11|  26614|   5.0|1391658574|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   148|  132|\n",
      "|   540|   20|\n",
      "|   597|  202|\n",
      "|   406|   73|\n",
      "|   442|  225|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite packages\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# View the ratings dataset\n",
    "ratings.show(5)\n",
    "\n",
    "# Filter to show only userIds less than 100\n",
    "ratings.filter(col(\"userId\") < 100).show(5)\n",
    "\n",
    "# Group data by userId, count song plays\n",
    "ratings.groupBy(\"userId\").count().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens Summary Statistics\n",
    "Let's take the groupBy() method a bit further.\n",
    "\n",
    "Once you've applied the .groupBy() method to a dataframe, you can subsequently run aggregate functions such as .sum(), .avg(), .min() and have the results grouped. This exercise will walk you through how this is done. The min and avg functions have been imported from pyspark.sql.functions for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per movie: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|11.030664019413193|\n",
      "+------------------+\n",
      "\n",
      "User with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per user: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|149.03725782414307|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, avg\n",
    "# Min num ratings for movies\n",
    "print(\"Movie with the fewest ratings: \")\n",
    "ratings.groupBy(\"movieId\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per movie\n",
    "print(\"Avg num ratings per movie: \")\n",
    "ratings.groupBy(\"movieId\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "ratings.groupBy(\"userId\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "ratings.groupBy(\"userId\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right. Users have at least 20 ratings and on average of 149 ratings. And movies have at least 1 rating with an average of 11 ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Schema\n",
    "As you know from previous chapters, Spark's implementation of ALS requires that movieIds and userIds be provided as integer datatypes. Many datasets need to be prepared accordingly in order for them to function properly with Spark. A common issue is that Spark thinks numbers are strings, and vice versa.\n",
    "\n",
    "Here, you'll use the .cast() method to address these types of problems. Let's take a look at the schema of the dataset to ensure it's in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .printSchema() to see the datatypes of the ratings dataset\n",
    "ratings.printSchema()\n",
    "\n",
    "# Tell Spark to convert the columns to the proper data types\n",
    "ratings = ratings.select(ratings.userId.cast(\"integer\"), ratings.movieId.cast(\"integer\"), ratings.rating.cast(\"double\"))\n",
    "\n",
    "# Call .printSchema() again to confirm the columns are now in the correct format\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test/train splits and build your ALS model\n",
    "You already know how to build an ALS model, having done it in the previous chapter. We will do that again, but we'll take some additional steps to fully build out a cross-validated model.\n",
    "\n",
    "First, let's import the requisite functions and create our train and test data sets in preparation for the cross validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False)\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tell Spark how to tune your ALS model\n",
    "Now we'll need to create a ParamGrid to tell Spark what hyperparameters we want it to tune, how to tune them, and then build out an evaluator so Spark can know how to measure the algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  64\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite items\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "           .addGrid(als.rank, [10, 50, 75, 100]) \\\n",
    "           .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n",
    "           .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "           .build()\n",
    "\n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your cross validation pipeline\n",
    "Now that we have our data, our train/test splits, our model, and our hyperparameter values, let's tell Spark how to cross validate our model so it can find the best combination of hyperparameters and return it to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_32ba8da08f78\n"
     ]
    }
   ],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model and Best Model Parameters\n",
    "Now that we have our cross validator, cv, built out, we can tell Spark to take our data, fit the ALS algorithm to it, and try the different combinations of hyperparameter values from our param_grid so that it can identify what values provide the smallest RMSE. Unfortunately, this takes too long to complete here, but for your reference, this is how it is done:\n",
    "\n",
    "```python\n",
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel\n",
    "```\n",
    "This code has been run separately, and the best_model has been identified and saved for you to use. Use the commands given to extract the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel\n",
    "\n",
    "# Print best_model\n",
    "print(type(best_model))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model.getRank())\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model.getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model.getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent work! If you'll notice, the best hyperparameter values were all in the middle of the ranges we provided. If they were on the low or high end, we would simply adjust our ranges accordingly. Given that they were in the middle, we could tune even further by narrowing our range to get even more precise hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and calculate RMSE\n",
    "Now that we have a model that is trained on our data and tuned through cross validation, we can see how it performs on the test dataframe. To do this, we'll calculate the RMSE.\n",
    "\n",
    "As a side note, the generation of test predictions takes more than a few minutes with this dataset. For this reason, the test predictions have been generated already and are provided here as a dataframe called test_predictions. For your reference, they are generated using this code: \n",
    "\n",
    "```python\n",
    "test_predictions = best_model.transform(test).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predictions \n",
    "test_predictions.show(5)\n",
    "\n",
    "# Calculate the RMSE of test_predictions\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. Remember that the RMSE is a rather subjective metric. Would you say that the RMSE in this case is sufficient to make meaningful recommendations? \n",
    "\n",
    "Interpretation: An RMSE of 0.633 means that on average the model predicts 0.633 above or below values of the original ratings matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Recommendations Make Sense\n",
    "Now that we have an understanding of how well our model performed, and have some confidence that it will provide recommendations that are relevant to users, let's actually look at recommendations made to a user and see if they make sense.\n",
    "\n",
    "The original ratings data is provided here as original_ratings. Take a look at user 60 and user 63's original ratings, and compare them to what ALS recommended for them. In your opinion, are the recommendations consistent with their original preferences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at user 60's ratings\n",
    "print(\"User 60's Ratings:\")\n",
    "original_ratings.filter(col(\"userId\") == 60).sort(\"rating\", ascending = False).show()\n",
    "\n",
    "# Look at the movies recommended to user 60\n",
    "print(\"User 60s Recommendations:\")\n",
    "recommendations.filter(col(\"userId\") == 60).show(5)\n",
    "\n",
    "# Look at user 63's ratings\n",
    "print(\"User 63's Ratings:\")\n",
    "original_ratings.filter(col(\"userId\") == 63).sort(\"rating\", ascending = False).show(5)\n",
    "\n",
    "# Look at the movies recommended to user 63\n",
    "print(\"User 63's Recommendations:\")\n",
    "recommendations.filter(col(\"userId\") == 63).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work. Does it look like the model picked up on user 60's preference for drama, crime, and comedy or user 63's preference for action, adventure, and drama?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:playground_py36]",
   "language": "python",
   "name": "conda-env-playground_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
